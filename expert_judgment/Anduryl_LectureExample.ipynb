{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02524d45",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://github.com/patmanas/figs/raw/main/LogoMORE.jpg\" WIDTH=150 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Probabilistic Modelling of real-world phenomena through ObseRvations and Elicitation (MORE)\n",
    "\n",
    "---\n",
    "\n",
    "## Expert Judgement - Anduryl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0484a",
   "metadata": {},
   "source": [
    "### Objetive\n",
    "\n",
    "Create a code that obtains the main indeces in Expert Judgement using Anduryl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9304f51",
   "metadata": {},
   "source": [
    "### Index\n",
    "\n",
    "0. Required Installations \n",
    "1. Load libraries\n",
    "2. Introduction\n",
    "3. Create Project\n",
    "4. Scores Calculations\n",
    "5. Combined Score\n",
    "6. Decision Maker\n",
    "7. Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52c98c1",
   "metadata": {},
   "source": [
    "### 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "845a7108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anduryl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f3a91",
   "metadata": {},
   "source": [
    "### 2. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1f1d5",
   "metadata": {},
   "source": [
    "Anduryl is a Python module and GUI for expert elicitation based on Cooke's classical method. Anduryl allows to set up your structured expert judgment project, calculate decision makers, robustness analysis and visualizations. In this Notebook an example on how tu use and apply Anduryl is given. For more information you can check the paper https://doi.org/10.1016/j.softx.2020.100497 and github repository https://github.com/grongen/anduryl.\n",
    "\n",
    "Fun fact, the original paper introducing ANDURIL (matlab predecesor of ANDURYL) includes the following explanation for the name: \n",
    "\"In order to avoid confusion of the minority of people, who are not familiar with the universe of Lord of the Rings by J.R.R. Tolkien, the authors would like to clarify the inspiration for the name of the developed Matlab toolbox. Andúril was the name of the sword of Aragorn, the son of Arathorn, which was reforged from the shards of Narsil (the sword that was used by Isildur to cut the One Ring from Sauron’s hand). Excalibur is also the name of the legendary sword of King Arthur. Similarly to the sword, the source code of EXCALIBUR software remained accessible only to a few worthy ones. Therefore, the researchers and practitioners could only admire and use the software without being able to further investigate and explore developments of the method. To change this, the existing software had to be “broken to pieces” and then “reforged”. Naturally, the name of the resulting new open-source Matlab toolbox is ANDURIL. Hopefully, this will help in bringing peace to troubled researchers and practitioners of Cooke’s classical model.\"\n",
    "\n",
    "\n",
    "Along this notebook, we will be working with the hypothetical example from the previous notebook. The case presents 3 differents experts that have answered 5 calibration questions (where a realization is known to the analysis but not to the experts at the moment of the elicitation and are used to objectively evaluate expert's assesment) and one question of interest (where no realization is present and is the main purpose of the expert judgement study). The experts answer every question providing respectively the quantiles 5th, 50eth and 95th of their uncertainty distributions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005cf588",
   "metadata": {},
   "source": [
    "### 3. Create Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff41c51c",
   "metadata": {},
   "source": [
    "In order to be able to use Anduryl, input files require a certain format. This will be discussed later in the \"File_info.ipynb\" notebook. For some general examples, the cases folder in the Github repository presents different examples. In the particular case of this notebook, the files example.dtt and example.rls contain the relevant infromation for the hypothetical case. The two different files are taken as input, one (the .dtt file) including the experts' responses and the other (.rls file) contains the realizations. For the experts file, information about the number of quantiles, the label of the question, the complete question and the units of the variable can be included. For the realizations file, the quantiles are not required and introducing the value -9.99500E+0002 is taken as a NaN as required for questions of interest.  With the code below we create an ANDRYL project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e02f5396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main project class.\n",
       "Properties:\n",
       " - assessments\n",
       " - experts\n",
       " - io\n",
       " - items\n",
       " - main_results\n",
       " - results\n",
       "Methods:\n",
       " - add_results_from_settings\n",
       " - calculate_decision_maker\n",
       " - calculate_expert_robustness\n",
       " - calculate_item_robustness\n",
       " - initialize\n",
       " - to_results"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create project and load Excalibur files\n",
    "file = 'maeslantkering'\n",
    "project = anduryl.Project()\n",
    "project.io.load_excalibur(f'./{file}.dtt', f'./{file}.rls')\n",
    "project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b017f83",
   "metadata": {},
   "source": [
    "We can see that when creating a project different \"Properties\" and \"Methods\" can be obtained and used. The properties contain the information about the realization, experts and scores. The methods can be applied to the different properties in order to perform different analyses. For example, obtaining the scores or a decision maker. \n",
    "\n",
    "In the code below we explore the \"items\", \"experts\" and \"assessments\" properties. With these properties later we can make analysis using Cooke's method in ANDURYL. \n",
    "\n",
    "For the items, the question, the scale and the realization are shown. In our example files, no description of the question or units are included but this is possible if introduced in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68ab66b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>realization</th>\n",
       "      <th>question</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QUESTION1</th>\n",
       "      <td>uni</td>\n",
       "      <td>7.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION2</th>\n",
       "      <td>uni</td>\n",
       "      <td>7.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION3</th>\n",
       "      <td>uni</td>\n",
       "      <td>10.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION4</th>\n",
       "      <td>uni</td>\n",
       "      <td>226.57</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION5</th>\n",
       "      <td>uni</td>\n",
       "      <td>249.29</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION6</th>\n",
       "      <td>uni</td>\n",
       "      <td>240.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION7</th>\n",
       "      <td>uni</td>\n",
       "      <td>212.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION8</th>\n",
       "      <td>uni</td>\n",
       "      <td>230.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION9</th>\n",
       "      <td>uni</td>\n",
       "      <td>250.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION10</th>\n",
       "      <td>uni</td>\n",
       "      <td>2.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION11</th>\n",
       "      <td>uni</td>\n",
       "      <td>39.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION12</th>\n",
       "      <td>uni</td>\n",
       "      <td>228.67</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION13</th>\n",
       "      <td>uni</td>\n",
       "      <td>300.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION14</th>\n",
       "      <td>uni</td>\n",
       "      <td>300.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION15</th>\n",
       "      <td>uni</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION16</th>\n",
       "      <td>uni</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION17</th>\n",
       "      <td>uni</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION18</th>\n",
       "      <td>uni</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION19</th>\n",
       "      <td>uni</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           scale  realization question unit\n",
       "QUESTION1    uni         7.00              \n",
       "QUESTION2    uni         7.00              \n",
       "QUESTION3    uni        10.00              \n",
       "QUESTION4    uni       226.57              \n",
       "QUESTION5    uni       249.29              \n",
       "QUESTION6    uni       240.00              \n",
       "QUESTION7    uni       212.00              \n",
       "QUESTION8    uni       230.00              \n",
       "QUESTION9    uni       250.00              \n",
       "QUESTION10   uni         2.00              \n",
       "QUESTION11   uni        39.00              \n",
       "QUESTION12   uni       228.67              \n",
       "QUESTION13   uni       300.00              \n",
       "QUESTION14   uni       300.00              \n",
       "QUESTION15   uni          NaN              \n",
       "QUESTION16   uni          NaN              \n",
       "QUESTION17   uni          NaN              \n",
       "QUESTION18   uni          NaN              \n",
       "QUESTION19   uni          NaN              "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(project.items.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ab64d",
   "metadata": {},
   "source": [
    "Then we can show a table with experts relevant metrics and values. As now calculations have been applied we would expect this table filled with NaN for now. The columns have the name of the expert, the information and calibration scores, number of answered questions, the weight and the user weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c0fe46db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Info. score total</th>\n",
       "      <th>Info. score real.</th>\n",
       "      <th>Calibration score</th>\n",
       "      <th>Answered seed items</th>\n",
       "      <th>Weight</th>\n",
       "      <th>User weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ex1</th>\n",
       "      <td>Ex1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex2</th>\n",
       "      <td>Ex2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Info. score total  Info. score real.  Calibration score  \\\n",
       "Ex1  Ex1                NaN                NaN                NaN   \n",
       "Ex2  Ex2                NaN                NaN                NaN   \n",
       "\n",
       "     Answered seed items  Weight  User weight  \n",
       "Ex1                  NaN     NaN          NaN  \n",
       "Ex2                  NaN     NaN          NaN  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(project.experts.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11a3bb",
   "metadata": {},
   "source": [
    "Before the calculations, we can have a look at the responses of the experts to each of the questions. Just to check that everything looks as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cc7b2a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"19\" valign=\"top\">Ex1</th>\n",
       "      <th>QUESTION1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION4</th>\n",
       "      <td>213.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION5</th>\n",
       "      <td>218.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION6</th>\n",
       "      <td>213.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION7</th>\n",
       "      <td>202.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION8</th>\n",
       "      <td>220.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION9</th>\n",
       "      <td>245.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION11</th>\n",
       "      <td>90.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION12</th>\n",
       "      <td>210.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION13</th>\n",
       "      <td>260.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION14</th>\n",
       "      <td>270.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION15</th>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION16</th>\n",
       "      <td>260.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION17</th>\n",
       "      <td>250.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION18</th>\n",
       "      <td>260.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION19</th>\n",
       "      <td>230.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"19\" valign=\"top\">Ex2</th>\n",
       "      <th>QUESTION1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION4</th>\n",
       "      <td>200.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION5</th>\n",
       "      <td>210.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION6</th>\n",
       "      <td>220.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>225.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION7</th>\n",
       "      <td>230.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION8</th>\n",
       "      <td>225.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION9</th>\n",
       "      <td>240.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION11</th>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION12</th>\n",
       "      <td>240.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION13</th>\n",
       "      <td>200.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION14</th>\n",
       "      <td>250.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION15</th>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION16</th>\n",
       "      <td>320.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION17</th>\n",
       "      <td>300.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION18</th>\n",
       "      <td>290.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUESTION19</th>\n",
       "      <td>180.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0.05   0.50   0.95\n",
       "Ex1 QUESTION1     9.0   16.0   26.0\n",
       "    QUESTION2     8.0   13.0   17.0\n",
       "    QUESTION3    18.0   31.0   51.0\n",
       "    QUESTION4   213.0  222.0  237.0\n",
       "    QUESTION5   218.0  224.0  237.0\n",
       "    QUESTION6   213.0  224.0  238.0\n",
       "    QUESTION7   202.0  212.0  222.0\n",
       "    QUESTION8   220.0  230.0  240.0\n",
       "    QUESTION9   245.0  250.0  255.0\n",
       "    QUESTION10    1.0    2.0    3.0\n",
       "    QUESTION11   90.0   96.0  100.0\n",
       "    QUESTION12  210.0  220.0  230.0\n",
       "    QUESTION13  260.0  290.0  310.0\n",
       "    QUESTION14  270.0  300.0  320.0\n",
       "    QUESTION15    4.0   20.0  130.0\n",
       "    QUESTION16  260.0  400.0  610.0\n",
       "    QUESTION17  250.0  380.0  580.0\n",
       "    QUESTION18  260.0  340.0  570.0\n",
       "    QUESTION19  230.0  320.0  540.0\n",
       "Ex2 QUESTION1     7.0   14.0   28.0\n",
       "    QUESTION2     7.0   15.0   30.0\n",
       "    QUESTION3     8.0   16.0   32.0\n",
       "    QUESTION4   200.0  205.0  225.0\n",
       "    QUESTION5   210.0  215.0  235.0\n",
       "    QUESTION6   220.0  225.0  225.1\n",
       "    QUESTION7   230.0  250.0  270.0\n",
       "    QUESTION8   225.0  255.0  275.0\n",
       "    QUESTION9   240.0  260.0  280.0\n",
       "    QUESTION10    0.0    0.1    1.0\n",
       "    QUESTION11   50.0   60.0   80.0\n",
       "    QUESTION12  240.0  260.0  290.0\n",
       "    QUESTION13  200.0  210.0  220.0\n",
       "    QUESTION14  250.0  290.0  310.0\n",
       "    QUESTION15   10.0   15.0   20.0\n",
       "    QUESTION16  320.0  350.0  370.0\n",
       "    QUESTION17  300.0  320.0  340.0\n",
       "    QUESTION18  290.0  310.0  320.0\n",
       "    QUESTION19  180.0  300.0  320.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(project.assessments.as_dict()).head(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab853c",
   "metadata": {},
   "source": [
    "### 4. Scores Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8c441",
   "metadata": {},
   "source": [
    "In this section we use ANDURYL in order to compute the same or very similar values as the ones calculated in the previous Notebook. Notice that in the exaple below no robusntess analysis is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a3003177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate decision maker with performance based weights\n",
    "project.calculate_expert_robustness(\n",
    "    weight_type='global',\n",
    "    overshoot=0.1,  # this is the k factor that adjusts the range of the support from the previous Notebook\n",
    "    max_exclude = 0 # this means no robustness analysis is performed  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb0e717",
   "metadata": {},
   "source": [
    "After the calculation, we can see that the table has been filled. As we have not defined user weights that column should remain as NaNs. Expert 1 shows a considerably higher Information Score compared to the other two, but very low Calibration Score. On the other hand, Expert 2 has a higher Calibration Score. Expert 3 seem to fall in between the other two. It is clear that the Calibration Score of Expert 1 penalizes him in the weights. Expert 2 and Expert 3 show a much higher weight with Expert 3 presenting the largest weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e25d4f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Info. score total</th>\n",
       "      <th>Info. score real.</th>\n",
       "      <th>Calibration score</th>\n",
       "      <th>Answered seed items</th>\n",
       "      <th>Weight</th>\n",
       "      <th>User weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ex1</th>\n",
       "      <td>Ex1</td>\n",
       "      <td>0.519847</td>\n",
       "      <td>0.648789</td>\n",
       "      <td>9.837546e-03</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.382495e-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex2</th>\n",
       "      <td>Ex2</td>\n",
       "      <td>0.913467</td>\n",
       "      <td>0.619275</td>\n",
       "      <td>7.754119e-07</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.801931e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Info. score total  Info. score real.  Calibration score  \\\n",
       "Ex1  Ex1           0.519847           0.648789       9.837546e-03   \n",
       "Ex2  Ex2           0.913467           0.619275       7.754119e-07   \n",
       "\n",
       "     Answered seed items        Weight  User weight  \n",
       "Ex1                 14.0  6.382495e-03          NaN  \n",
       "Ex2                 14.0  4.801931e-07          NaN  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(project.experts.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0624bc",
   "metadata": {},
   "source": [
    "### 5. Combined Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497bcd93",
   "metadata": {},
   "source": [
    "Once the different scores are calculated, they can actually be combined into the Combined Score. The score is defined as the product of the Calibration Score and the Information Score:\n",
    "\n",
    "$$CS(e) = Cal(e) * Inf(e)$$\n",
    "\n",
    "This combination is relevant for the calculation of the Decision Maker and the weights required for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f09ecee",
   "metadata": {},
   "source": [
    "### 6. Decision Maker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fde6574",
   "metadata": {},
   "source": [
    "When having multiple ($N$) experts, we can create what is known as de Decision Maker ($DM$) by combining the different experts using weights. The PDF and CDF of the $DM$ are as follows:\n",
    "\n",
    "$$f_{DM} = \\sum \\limits _{i=1} ^{N} w_{i} f_{i}$$\n",
    "$$F_{DM} = \\sum \\limits _{i=1} ^{N} w_{i} F_{i}$$\n",
    "\n",
    "Where $f_{i}$ corresponds to the PDF, $F_{i}$ to the CDF and $w_{i}$ the weight assigned to the expert $i$. There are different ways to define the weights. One way is to provide equal weights to each of the experts, generating the Equal Weight DM. Another option is to make use of the $CS$ to create a Performance-based Weight $DM$. The weights for this case are defined as:\n",
    "\n",
    "$$w_{i} = \\frac{CS(e_{i})}{\\sum \\limits _{j=1} ^{N} CS(e_{j})}$$\n",
    "\n",
    "On top that, if we don't want experts with very low statistical accuracy, we can impose a restriction by only using experts with a Calibration Score higher than a particulat threshold (often $0.05$, why?). \n",
    "\n",
    "Notice that the Decision Maker presents can be treated a another expert and its Calibration and Information Scores can be computed and compared to the actual experts.\n",
    "\n",
    "In the following blocks, you can see an example on how to calculate a Decision Maker using Anduryl and how to make plots of the CDFs for the different questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "437bf880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate decision maker with global weights, using performance based\n",
    "project.calculate_decision_maker(\n",
    "    weight_type='global',\n",
    "    overshoot=0.1,\n",
    "    exp_id='DMgl',\n",
    "    calpower=1.0, # Calibration power, relative weight of the calibration compared\n",
    "                  # to the information score\n",
    "    exp_name='Decision Maker global weights',\n",
    "    alpha=0.0,    # Significance level for the calibration score. Experts with a lower\n",
    "                  # calibration score get zero weight. If None, the weights\n",
    "                  # are returnes for all possible significance levels \n",
    "                  # (unique calibration scores)\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "project.experts.user_weights[0:3] = [1.0, 1.0, 1.0] # Equal weight DM\n",
    "\n",
    "# Calculate decision maker with user defined weights\n",
    "project.calculate_decision_maker(\n",
    "    weight_type='user',\n",
    "    overshoot=0.1,\n",
    "    exp_id='DMeq',\n",
    "    calpower=1.0,\n",
    "    exp_name='Decision Maker equal weights',\n",
    "    alpha=0.0,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0241d905",
   "metadata": {},
   "source": [
    "The DM can be calculated in multiple ways, it can be equal weight DM, setting as 1 the user weights of each of the experts, or performance based DM which is the example shown in the code above using global.\n",
    "\n",
    "After we calculate the DM, you can see that it appears as another expert with specific scores and weights. We have also included User weights, so that column is filled now. By looking at the weights, it falls in between the very low Expert 1 and the other two experts. In the information Score, it seems to perform worse than all the other experts but in the Calibration Score is between Experts 2 and 3. Remember that the DM is a weighted combination of the Experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b63b8ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Info. score total</th>\n",
       "      <th>Info. score real.</th>\n",
       "      <th>Calibration score</th>\n",
       "      <th>Answered seed items</th>\n",
       "      <th>Weight</th>\n",
       "      <th>User weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ex1</th>\n",
       "      <td>Ex1</td>\n",
       "      <td>0.519847</td>\n",
       "      <td>0.648789</td>\n",
       "      <td>9.837546e-03</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.382495e-03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ex2</th>\n",
       "      <td>Ex2</td>\n",
       "      <td>0.913467</td>\n",
       "      <td>0.619275</td>\n",
       "      <td>7.754119e-07</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.801931e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMgl</th>\n",
       "      <td>Decision Maker global weights</td>\n",
       "      <td>0.518671</td>\n",
       "      <td>0.647193</td>\n",
       "      <td>9.837546e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.366795e-03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMeq</th>\n",
       "      <td>Decision Maker equal weights</td>\n",
       "      <td>0.149618</td>\n",
       "      <td>0.109834</td>\n",
       "      <td>7.235007e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.946474e-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name  Info. score total  Info. score real.  \\\n",
       "Ex1                             Ex1           0.519847           0.648789   \n",
       "Ex2                             Ex2           0.913467           0.619275   \n",
       "DMgl  Decision Maker global weights           0.518671           0.647193   \n",
       "DMeq   Decision Maker equal weights           0.149618           0.109834   \n",
       "\n",
       "      Calibration score  Answered seed items        Weight  User weight  \n",
       "Ex1        9.837546e-03                 14.0  6.382495e-03          1.0  \n",
       "Ex2        7.754119e-07                 14.0  4.801931e-07          1.0  \n",
       "DMgl       9.837546e-03                  NaN  6.366795e-03          1.0  \n",
       "DMeq       7.235007e-02                  NaN  7.946474e-03          NaN  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(project.experts.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fce648",
   "metadata": {},
   "source": [
    "Finally, the results the resulting PDF of the experts, including the DM, can be plotted using the CDF of each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a78e6c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the question for which we want to plot the different CDFs\n",
    "item = 'QUESTION4'\n",
    "itemnr = project.items.ids.index(item)\n",
    "\n",
    "# Get experts assessments for the item\n",
    "itemassessment = project.assessments.get_array(experts='actual')[:, :, itemnr]\n",
    "# Get bounds for the item\n",
    "bounds = project.assessments.get_bounds(overshoot=0.1)\n",
    "lower, upper = bounds[0][itemnr], bounds[1][itemnr]\n",
    "\n",
    "# Plot experts' cdfs\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "for i, assessment in enumerate(itemassessment):\n",
    "    ax.plot(np.r_[lower, assessment, upper], np.r_[0.0, project.assessments.quantiles, 1.0],\n",
    "            label='{} (w={:.3f})'.format(project.experts.ids[i], project.experts.comb_score[i] / sum(project.experts.comb_score)))\n",
    "    \n",
    "# Plot DM's cdf\n",
    "ax.plot(*project.assessments.full_cdf['DMgl'][itemnr].T, label='DMgl', marker='.', ms=4, color='0.4', ls='--', lw=2)\n",
    "ax.plot(*project.assessments.full_cdf['DMeq'][itemnr].T, label='DMeq', marker='.', ms=4, color='0.8', ls='--', lw=2)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(project.items.questions[itemnr])\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel('CDF');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d86aff",
   "metadata": {},
   "source": [
    "### 7. Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f5e671",
   "metadata": {},
   "source": [
    "A way of checking the robustness of the project is by removing one or multiple items or experts from the project in turn, and checking the resulting information and calibration scores. If these values will change a lot, it shows that the number of items or experts might be a bit too low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b2f46e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude up to four items\n",
    "project.calculate_item_robustness(\n",
    "    weight_type='global',\n",
    "    overshoot=0.1,\n",
    "    max_exclude=4,\n",
    "    min_exclude=0,\n",
    "    calpower=1.0,\n",
    "    alpha=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c06d7a",
   "metadata": {},
   "source": [
    "In the next table, you can see the score changes when different questions are extracted of the calculations. As this is an artifitial example, the Calibration Score has a extrange behaviour, where there is no change of the score or only one single change when one or multiple questions are removed. You are now encouraged to take some of the examples on the github repository that you will find at the end of this notebook and try some of the different examples you can find there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a6af90e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info score total</th>\n",
       "      <th>Info score realizations</th>\n",
       "      <th>Calibration score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.518671</td>\n",
       "      <td>0.647193</td>\n",
       "      <td>0.009838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(QUESTION1,)</th>\n",
       "      <td>0.538335</td>\n",
       "      <td>0.684306</td>\n",
       "      <td>0.044087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(QUESTION2,)</th>\n",
       "      <td>0.504969</td>\n",
       "      <td>0.638108</td>\n",
       "      <td>0.044087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(QUESTION3,)</th>\n",
       "      <td>0.536559</td>\n",
       "      <td>0.681847</td>\n",
       "      <td>0.044087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(QUESTION4,)</th>\n",
       "      <td>0.512565</td>\n",
       "      <td>0.648628</td>\n",
       "      <td>0.007438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(QUESTION10, QUESTION11, QUESTION12, QUESTION13)</th>\n",
       "      <td>0.192171</td>\n",
       "      <td>0.198116</td>\n",
       "      <td>0.013974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(QUESTION10, QUESTION11, QUESTION12, QUESTION14)</th>\n",
       "      <td>0.427113</td>\n",
       "      <td>0.561269</td>\n",
       "      <td>0.013974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(QUESTION10, QUESTION11, QUESTION13, QUESTION14)</th>\n",
       "      <td>0.461528</td>\n",
       "      <td>0.612890</td>\n",
       "      <td>0.013974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(QUESTION10, QUESTION12, QUESTION13, QUESTION14)</th>\n",
       "      <td>0.372956</td>\n",
       "      <td>0.479891</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(QUESTION11, QUESTION12, QUESTION13, QUESTION14)</th>\n",
       "      <td>0.391522</td>\n",
       "      <td>0.507884</td>\n",
       "      <td>0.013974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1471 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Info score total  \\\n",
       "None                                                      0.518671   \n",
       "(QUESTION1,)                                              0.538335   \n",
       "(QUESTION2,)                                              0.504969   \n",
       "(QUESTION3,)                                              0.536559   \n",
       "(QUESTION4,)                                              0.512565   \n",
       "...                                                            ...   \n",
       "(QUESTION10, QUESTION11, QUESTION12, QUESTION13)          0.192171   \n",
       "(QUESTION10, QUESTION11, QUESTION12, QUESTION14)          0.427113   \n",
       "(QUESTION10, QUESTION11, QUESTION13, QUESTION14)          0.461528   \n",
       "(QUESTION10, QUESTION12, QUESTION13, QUESTION14)          0.372956   \n",
       "(QUESTION11, QUESTION12, QUESTION13, QUESTION14)          0.391522   \n",
       "\n",
       "                                                  Info score realizations  \\\n",
       "None                                                             0.647193   \n",
       "(QUESTION1,)                                                     0.684306   \n",
       "(QUESTION2,)                                                     0.638108   \n",
       "(QUESTION3,)                                                     0.681847   \n",
       "(QUESTION4,)                                                     0.648628   \n",
       "...                                                                   ...   \n",
       "(QUESTION10, QUESTION11, QUESTION12, QUESTION13)                 0.198116   \n",
       "(QUESTION10, QUESTION11, QUESTION12, QUESTION14)                 0.561269   \n",
       "(QUESTION10, QUESTION11, QUESTION13, QUESTION14)                 0.612890   \n",
       "(QUESTION10, QUESTION12, QUESTION13, QUESTION14)                 0.479891   \n",
       "(QUESTION11, QUESTION12, QUESTION13, QUESTION14)                 0.507884   \n",
       "\n",
       "                                                  Calibration score  \n",
       "None                                                       0.009838  \n",
       "(QUESTION1,)                                               0.044087  \n",
       "(QUESTION2,)                                               0.044087  \n",
       "(QUESTION3,)                                               0.044087  \n",
       "(QUESTION4,)                                               0.007438  \n",
       "...                                                             ...  \n",
       "(QUESTION10, QUESTION11, QUESTION12, QUESTION13)           0.013974  \n",
       "(QUESTION10, QUESTION11, QUESTION12, QUESTION14)           0.013974  \n",
       "(QUESTION10, QUESTION11, QUESTION13, QUESTION14)           0.013974  \n",
       "(QUESTION10, QUESTION12, QUESTION13, QUESTION14)           0.000799  \n",
       "(QUESTION11, QUESTION12, QUESTION13, QUESTION14)           0.013974  \n",
       "\n",
       "[1471 rows x 3 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robres = project.main_results.item_robustness\n",
    "index = [val[:] if val else 'None' for val in list(robres.keys())]\n",
    "pd.DataFrame(data=robres.values(), index=index, columns=['Info score total' ,'Info score realizations', 'Calibration score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25112991",
   "metadata": {},
   "source": [
    "When more questions are extracted, the variation of the Information Score grows. This means that the calculations results are more sensitive when more questions are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "086ecf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the results per number of excluded items\n",
    "robres = project.main_results.item_robustness\n",
    "values = {}\n",
    "for key, value in robres.items():\n",
    "    # Add dictionary item if it does not exist yet\n",
    "    if len(key) not in values.keys():\n",
    "        values[len(key)] = []\n",
    "    # Append total information score (the 1st value)\n",
    "    values[len(key)].append(value[0])\n",
    "        \n",
    "# Show the variation in calibration and information scores.\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(values.values(), positions=list(values.keys()));\n",
    "ax.set_xlabel('Number of excluded items')\n",
    "ax.set_ylabel('Total Information score')\n",
    "ax.set_title('Variation for excluding up to 4 items');\n",
    "ax.grid(axis='x')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0cd9b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the results per number of excluded items\n",
    "robres = project.main_results.item_robustness\n",
    "values = {}\n",
    "for key, value in robres.items():\n",
    "    # Add dictionary item if it does not exist yet\n",
    "    if len(key) not in values.keys():\n",
    "        values[len(key)] = []\n",
    "    # Append information score with realizations\n",
    "    values[len(key)].append(value[1])\n",
    "        \n",
    "# Show the variation in calibration and information scores.\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(values.values(), positions=list(values.keys()));\n",
    "ax.set_xlabel('Number of excluded items')\n",
    "ax.set_ylabel('Information Score with realizations')\n",
    "ax.set_title('Variation for excluding up to 4 items');\n",
    "ax.grid(axis='x')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ac6161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the results per number of excluded items\n",
    "robres = project.main_results.item_robustness\n",
    "values = {}\n",
    "for key, value in robres.items():\n",
    "    # Add dictionary item if it does not exist yet\n",
    "    if len(key) not in values.keys():\n",
    "        values[len(key)] = []\n",
    "    # Append calibration score (the 3th value, index 2 since Python is zero-based)\n",
    "    values[len(key)].append(value[2])\n",
    "        \n",
    "# Show the variation in calibration and information scores.\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(values.values(), positions=list(values.keys()));\n",
    "ax.set_xlabel('Number of excluded items')\n",
    "ax.set_ylabel('Calibration score')\n",
    "ax.set_title('Variation for excluding up to 4 items');\n",
    "ax.grid(axis='x')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f415d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
